{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhoRtLOtPp6lFNih1ugThE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRAFTYPROGRAMMER826/IITGN-SRIP2025-IP0NB0000020/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktrRGyPriSsK",
        "outputId": "5df83dd9-ce32-487c-811f-c28ec4ad0349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-02 08:15:36--  https://archive.ics.uci.edu/static/public/240/human+activity+recognition+using+smartphones.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip             [      <=>           ]  58.18M  11.9MB/s    in 12s     \n",
            "\n",
            "2025-03-02 08:15:50 (4.74 MB/s) - ‘dataset.zip’ saved [61005872]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O \"dataset.zip\" \"https://archive.ics.uci.edu/static/public/240/human+activity+recognition+using+smartphones.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"dataset.zip\" -d \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-Nr-O5wao6q",
        "outputId": "cf559d6e-af5d-4882-aaf9-e261a5e594f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip\n",
            " extracting: /content/UCI HAR Dataset.names  \n",
            " extracting: /content/UCI HAR Dataset.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"UCI HAR Dataset.zip\" -d \"/content/UCI HAR/\""
      ],
      "metadata": {
        "id": "eNnu3yLfbE6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b470aed-c3de-4ed7-e137-4937f7d42c01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  UCI HAR Dataset.zip\n",
            "   creating: /content/UCI HAR/UCI HAR Dataset/\n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/.DS_Store  \n",
            "   creating: /content/UCI HAR/__MACOSX/\n",
            "   creating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/\n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._.DS_Store  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/activity_labels.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._activity_labels.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/features.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._features.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/features_info.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._features_info.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/README.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._README.txt  \n",
            "   creating: /content/UCI HAR/UCI HAR Dataset/test/\n",
            "   creating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt  \n",
            "   creating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/\n",
            "   creating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_x_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_y_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_z_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_x_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_y_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_z_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_x_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_y_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_z_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/._Inertial Signals  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/subject_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/._subject_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/X_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/._X_test.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/test/y_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/test/._y_test.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._test  \n",
            "   creating: /content/UCI HAR/UCI HAR Dataset/train/\n",
            "   creating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt  \n",
            "   creating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/\n",
            "   creating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_x_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/body_acc_y_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_y_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/body_acc_z_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_z_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/body_gyro_x_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_x_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/body_gyro_y_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_y_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/body_gyro_z_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_z_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_x_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_y_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_z_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/._Inertial Signals  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/subject_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/._subject_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/X_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/._X_train.txt  \n",
            "  inflating: /content/UCI HAR/UCI HAR Dataset/train/y_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/train/._y_train.txt  \n",
            "  inflating: /content/UCI HAR/__MACOSX/UCI HAR Dataset/._train  \n",
            "  inflating: /content/UCI HAR/__MACOSX/._UCI HAR Dataset  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# importing the necessary libraries"
      ],
      "metadata": {
        "id": "6spV3J1ZeiT_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_path = \"/content/UCI HAR/Dataset/train/X_train.txt\"\n",
        "y_train_path = \"/content/UCI HAR/Dataset/train/y_train.txt\"\n",
        "X_test_path = \"/content/UCI HAR/Dataset/test/X_test.txt\"\n",
        "y_test_path = \"/content/UCI HAR/Dataset/test/y_test.txt\"\n",
        "\n",
        "#defining the paths of the trainning and the test data files along with the lables\n",
        "print(y_train.shape)\n",
        "\n",
        "X_train = np.loadtxt(X_train_path)\n",
        "y_train = np.loadtxt(y_train_path).astype(int).ravel()\n",
        "X_test = np.loadtxt(X_test_path)\n",
        "y_test = np.loadtxt(y_test_path).astype(int).ravel()\n",
        "print(y_train.shape)\n",
        "\n",
        "# converting the x train and x test files to a numpy array as they only contain the numerical values\n",
        "# and the processing of a numpy array is faster than a pandas dataframe\n",
        "\n",
        "# we also convert the y train and y test files to type integers just in case there ois andy decimal value in the lables\n",
        "#  along with that we use the ravel function to convert the lables to only 1 d format which is accepted by the lstm model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0engjMoD7VCw",
        "outputId": "8f8d5829-fdfd-4e5e-fb10-1dfd47ad2bd8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7352,)\n",
            "(7352,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# applying the sandard scaler method from the scikit library\n",
        "# using Z score normalization scaling method for making the data centered around\n",
        "# zero and reducing the diverse range of values (X scaled = ([X- meaan]/ Standard Deviation)"
      ],
      "metadata": {
        "id": "GIwDmMEm7b5A"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "#originally the x test and train files were in a two  dimensional format.\n",
        "# but we convert them to a three dimensional format because thew lstm model is generally\n",
        "# used to predict real time data so it expects three dimensional data\n",
        "# each dimension corresponds to format(lables, timesteps , features)\n",
        "# lables denote the type of outcome to be predicted here it is the type of activity\n",
        "# timesteps denote the  number of samples for which the features would be evaluated and the lables would be predicted\n",
        "# here we don't have any real time data so we use timesteps =1 which suggests that features of all the samples would be\n",
        "# evaluated in a single iteration and the p[redictions would be generated in a single teration too\n",
        "#"
      ],
      "metadata": {
        "id": "fB8LpLVa7vt0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train - 1)  # Adjust labels to start from 0 because the traditional deep learning models\n",
        "# expect the lables to start from zero and the y train and test files originally had lables from 1 to 6\n",
        "y_test = to_categorical(y_test - 1)"
      ],
      "metadata": {
        "id": "dXIxuCfA7wRU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(1, X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "# using the sequential function from keras package of tensorflow library\n",
        "# creating layer of lstm neural network with 64 neurons with shape (timesteps,features) by excluding the lables\n",
        "# return_sequences=True  Ensures the output is a sequence and not the pattern detected by final state\n",
        "#  (needed for stacking multiple LSTMs)\n",
        "# but it does not make any difference her because we only have 1 timestep so true and false will behave the same\n",
        "# droupout=0.2 suggests 20% neurons would be randomly switched off to prevent overfitting of data\n",
        "# another layer of 32 neurons to refine and process the pattern analysed by first layer it also follows dropout= 0.2\n",
        "# the dense layer has  6 neurons each correspondingnto one of the lables of the dataset\n",
        "# enabling softmax causes each neuron to generate probabilities for the occurance of their respective lables based\n",
        "# test data features\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A6G1Gr97zc0",
        "outputId": "9426acf6-72b3-4e0e-cf24-5c53283479f0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7352, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Adam (Adaptive Moment Estimation) Accuracy= Total Samples / Correct Predictions"
      ],
      "metadata": {
        "id": "vKVQVROX72cH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "# the model checks the entire dataset 20 times  checking 32 samples at once and checks from seperate test data\n",
        "# and the weights are reset once again by backpropagation and the process goes on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd6x-_Vm75ze",
        "outputId": "3d89621d-d96c-49b5-f03f-7787f84359b8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 1.0464 - val_accuracy: 0.9379 - val_loss: 0.1842\n",
            "Epoch 2/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9514 - loss: 0.1476 - val_accuracy: 0.9393 - val_loss: 0.1716\n",
            "Epoch 3/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0850 - val_accuracy: 0.9342 - val_loss: 0.1955\n",
            "Epoch 4/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0777 - val_accuracy: 0.9372 - val_loss: 0.1836\n",
            "Epoch 5/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0609 - val_accuracy: 0.9423 - val_loss: 0.1779\n",
            "Epoch 6/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0702 - val_accuracy: 0.9382 - val_loss: 0.2063\n",
            "Epoch 7/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0483 - val_accuracy: 0.9369 - val_loss: 0.2096\n",
            "Epoch 8/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9832 - loss: 0.0477 - val_accuracy: 0.9399 - val_loss: 0.2179\n",
            "Epoch 9/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0530 - val_accuracy: 0.9430 - val_loss: 0.2018\n",
            "Epoch 10/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0463 - val_accuracy: 0.9396 - val_loss: 0.2038\n",
            "Epoch 11/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0414 - val_accuracy: 0.9243 - val_loss: 0.2710\n",
            "Epoch 12/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0351 - val_accuracy: 0.9444 - val_loss: 0.2086\n",
            "Epoch 13/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0330 - val_accuracy: 0.9474 - val_loss: 0.1942\n",
            "Epoch 14/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 0.0367 - val_accuracy: 0.9372 - val_loss: 0.2349\n",
            "Epoch 15/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.0476 - val_accuracy: 0.9464 - val_loss: 0.2086\n",
            "Epoch 16/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0276 - val_accuracy: 0.9430 - val_loss: 0.1956\n",
            "Epoch 17/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0339 - val_accuracy: 0.9237 - val_loss: 0.3439\n",
            "Epoch 18/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0319 - val_accuracy: 0.9498 - val_loss: 0.2145\n",
            "Epoch 19/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0184 - val_accuracy: 0.9491 - val_loss: 0.1884\n",
            "Epoch 20/20\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0229 - val_accuracy: 0.9410 - val_loss: 0.2273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"LSTM Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"losses:{loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EamPAIgh78sa",
        "outputId": "16eba29a-7359-4ac3-ab2f-ca3fc310c3ba"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1987\n",
            "LSTM Model Accuracy: 0.9410\n",
            "losses:0.2273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EOs7ZaqS8FkB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}